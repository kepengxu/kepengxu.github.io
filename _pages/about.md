---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

<!-- # Seeking Visiting scholar
Seeking opportunities for Visiting scholar Ph.D -->

# Profile
I am currently pursuing a Ph.D. at Xidian University, focusing on research areas including video image enhancement, high dynamic range video generation, and video compression. 

I am looking for interdisciplinary collaborative research, including but not limited to, **multi-modal perception and understanding**.

## Research and Publications
To date, I have authored over 10 scholarly articles and actively participate as a peer reviewer for top-tier conferences such as CVPR, ICCV, ACM MM, and AAAI. My work primarily explores the intersections of image processing and data compression in digital media technologies.

## Achievements
My research team secured the fourth place in the objective quality category at the CLIC 2022 video compression challenge. I am also a recipient of the National Scholarship among other awards.

<!-- My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# üî• News
- *2025.05*: üìù 3 papers accepted by IJCAI in May 2025
- *2025.01*: üéâ Received funding from the 2024 China Association for Science and Technology Young Talent Support Project Doctoral Special Program
- *2024.12*: üéâ As a technical support, the restoration of the historical video of the 25th anniversary of Macau's return to China was realized.  Related reports see[CCTV](https://app.cctv.com/special/m/livevod/index.html?vtype=2&guid=9c7d772eff194040bd6d126d78b795bb&vsetId=VSET100431636664),[WeChat](https://app.cctv.com/special/m/livevod/index.html?vtype=2&guid=9c7d772eff194040bd6d126d78b795bb&vsetId=VSET100431636664),[Â§ÆËßÜÁΩë](https://weibo.com/u/3266943013),[Xidian News](https://news.xidian.edu.cn/info/2106/245326.htm),[Collect](https://github.com/kepengxu/kepengxu.github.io/blob/main/images/report.png)
- *2024.10*: üéâ Invited by CVPR'2025 as Reviewer.
- *2024.08*: üéâ !üî• 	ü§óü§óü§ó The Inference Code of PGTFormer is in huggingface [PGTFormer][![](https://img.shields.io/github/stars/kepengxu/PGTFormer?style=social&label=Code+Stars)](https://github.com/kepengxu/PGTFormer)(Video face Restoration is released).
- *2024.08*: üéâ !üî• 	5 Paper is accepted by ACM MM Workshop 2024.
- *2024.07*: üéâ !üî• 	`An End-to-End Real-World Camera Imaging Pipeline` is accepted by ACM MM 2024.
- *2024.05*: üéâ Invited by NeurIPS as Reviewer.
- *2024.04*: üéâ `Beyond Alignment: Blind Video Face Restoration via Parsing-Guided Temporal-Coherent Transformer`is accepted by IJCAI 2024.
- *2024.03*: üéâ Invited by MM as Program Reviewer.


<!-- - *2023.05*: üéâ Five papers are accepted by ACL 2023
- *2023.01*: DiffSinger was introduced in [a very popular video](https://www.bilibili.com/video/BV1uM411t7ZJ) (2000k+ views) in Bilibili!
- *2023.01*: I join TikTok <img src='./images/tiktok.png' style='width: 6em;'> as a speech research scientist in Singapore!
- *2022.02*: I release a modern and responsive academic personal [homepage template](https://github.com/RayeRen/acad-homepage.github.io). Welcome to STAR and FORK! -->

# üìù Publications 


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI-25</div><img src='images\realhdrtvnet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Beyond Feature Mapping GAP: Integrating Real HDRTV Priors for Superior SDRTV-to-HDRTV Conversion](https://arxiv.org/abs/2411.10775)

**Kepeng Xu**, Li Xu, Gang He, Zhiqiang Zhang, Wenxin Yu, Shihao Wang, Dajiang Zhou, Yunsong Li.


[**Project**] <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- A more generalizable real-world SDRTV to HDRTV conversion method
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI-25</div><img src='images\hdfacerestoration.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Unleashing the Potential of Transformer Flow for Photorealistic Face Restoration]

**Kepeng Xu**, Li Xu, Gang He, Wei Chen, Xianyun Wu, Wenxin Yu.


[**Project**](https://kepengxu.github.io/projects/onmiface/) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Transformer Flow Matching Drive High-Quality Face Restoration
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI-25</div><img src='images\fckt.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FCKT: Fine-Grained Cross-Task Knowledge Transfer with Semantic Contrastive Learning for Targeted Sentiment Analysis]

Wei Chen, Zhao Zhang, Meng Yuan, **Kepeng Xu**, Fuzhen Zhuang.


[**Project**] <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- This paper introduces FCKT, a method that better connects aspect extraction and sentiment prediction to improve targeted sentiment analysis.


</div>
</div>




<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACMMM 2024</div><img src='images/framework.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[An End-to-End Real-World Camera Imaging Pipeline](https://arxiv.org/abs/2411.10773)

**Kepeng Xu**, Zijia Ma, Li Xu et al.[![](https://img.shields.io/github/stars/kepengxu/RealCamNet?style=social&label=Code+Stars)](https://github.com/kepengxu/RealCamNet)


[**Project**](https://kepengxu.github.io/projects/realcamnet/) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- End-to-end imaging pipeline for complex distortions
</div>
</div>




<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IJCAI 2024</div><img src='images/ijcaiimage.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Beyond Alignment: Blind Video Face Restoration via Parsing-Guided Temporal-Coherent Transformer](https://arxiv.org/abs/2404.13640)

**Kepeng Xu**, Li Xu, Gang He et al.[![](https://img.shields.io/github/stars/kepengxu/PGTFormer?style=social&label=Code+Stars)](https://github.com/kepengxu/PGTFormer)


[**Project**](https://kepengxu.github.io/projects/pgtformer/) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Clearer and more consistent video face restoration.

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Awesome-SDRTV-to-HDRTV</div><img src='images/hdrimage.jpg' alt="sym" width="40%"></div></div>
<div class='paper-box-text' markdown="1">

[Awesome-SDRTV-to-HDRTV](https://github.com/kepengxu/Awesome-SDRTV-to-HDRTV-Video-nverse-Tone-Mapping/tree/main)


</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Awesome-Video Face Restoration</div><img src='images/vfrawe.png' alt="sym" width="40%"></div></div>
<div class='paper-box-text' markdown="1">

[Awesome-Video Face Restoration](https://github.com/kepengxu/Awesome-Video-Face-Restoration/tree/main)


</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2022</div><img src='images/mmimage.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SDRTV-to-HDRTV via Hierarchical Dynamic Context Feature Mapping](https://arxiv.org/abs/2207.00319)

Gang He, **Kepeng Xu***, Li Xu et al.[![](https://img.shields.io/github/stars/iii935/HDCFM?style=social&label=Code+Stars)](https://github.com/iii935/HDCFM)




<!-- - `AAAI 2024` [Emotion Rendering for Conversational Speech Synthesis with Heterogeneous Graph-Based Context Modeling](https://arxiv.org/abs/2312.11947), Rui Liu, Yifan Hu, **Yi Ren**, et al. [![](https://img.shields.io/github/stars/walker-hyf/ECSS?style=social&label=Code+Stars)](https://github.com/walker-hyf/ECSS) -->

[**Project**](https://arxiv.org/abs/2207.00319) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Provides better HDR conversion quality.
</div>
</div>

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

- `TGRS'25` [	
IOVarNet: Inner-outer Variation Synergy Network for Infrared Small Target Detection], Shangwei Deng,Qianwen Ma,Bincheng Li,Liaoran Jin,**Kepeng Xu**,Shangqi Deng,Xiaobo Li,Haofeng Hu.

- `ACMMM24 EMCLR` [	
Neural Video Compression with Re-Parametrisation Scene Content-Adaptive Network], **Kepeng Xu**, Gang He‚Ä† et al.
- `ACMMM24 EMCLR` [	
Adaptive Dual-Domain Debanding: A Novel Algorithm for Image and Video Enhancement], **Kepeng Xu**, Gang He‚Ä† et al.
- `ACMMM24 Meet4MM` [High-dynamic Range Video Generation Method Based On Adaptive Priors Dynamic Mapping], Gang He, SiqiWang,**Kepeng Xu** et al.
- `ACMMM24 QoEVMA` [	
No-Reference Image Quality Assessment via Local and Global Multi-Scale Feature Integration], **Kepeng Xu**, Gang He‚Ä† et al.
- `ACMMM24 QoEVMA` [	
Banding Detection via Adaptive Global Frequency Domain Analysis],  Gang He,**Kepeng Xu** ‚Ä† et al. 




- `Arxiv` [Towards Robust SDRTV-to-HDRTV via Dual Inverse Degradation Network](https://arxiv.org/html/2307.03394v2), **Kepeng Xu***, Li Xu*, Gang He‚Ä† et al. 
<!-- [![](https://img.shields.io/github/stars/iii935/DIDNet?style=social&label=Code+Stars)](https://github.com/iii935/DIDNet) -->

- `CLIC 22` [Hybrid video coding scheme based on VVC and spatio-temporal attention convolution neural network](https://openaccess.thecvf.com/content/CVPR2022W/CLIC/papers/He_Hybrid_Video_Coding_Scheme_Based_on_VVC_and_Spatio-Temporal_Attention_CVPRW_2022_paper.pdf), Gang He, **Kepeng Xu*** et al.

- `CVPRW 22` [DNAS: A Decoupled Global Neural Architecture Search Method](https://openaccess.thecvf.com/content/CVPR2022W/NAS/papers/Xu_DNASA_Decoupled_Global_Neural_Architecture_Search_Method_CVPRW_2022_paper.pdf), **Kepeng Xu***, Gang He. 

- `Arxiv` [Sdrtv-to-hdrtv conversion via spatial-temporal feature fusion](https://arxiv.org/pdf/2211.02297), **Kepeng Xu***, Li Xu et al. 

- `ICONIP` [Inpainting with Sketch Reconstruction and Comprehensive Feature Selection](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I1x3S4gAAAAJ&citation_for_view=I1x3S4gAAAAJ:UeHWp8X0CEIC), S Li, L Lu, K Xu et al. 


- `ICONIP` [LPI-Net: Lightweight Inpainting Network with Pyramidal Hierarchy](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I1x3S4gAAAAJ&citation_for_view=I1x3S4gAAAAJ:u-x6o8ySG0sC), S Li, L Lu, Z Li, K Xu et al. 

- `ICMEW` [Segmentation of building footprints with xception and iouloss](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I1x3S4gAAAAJ&citation_for_view=I1x3S4gAAAAJ:u-x6o8ySG0sC), K Xu, Y Zhang, W Yu et al. 

- `ICIP` [Interactive separation network for image inpainting](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I1x3S4gAAAAJ&citation_for_view=I1x3S4gAAAAJ:d1gkVwhDpl0C), S Li, L Lu, Z Zhang, X Cheng, K Xu et al. 

- `ICONIP` [IRSNET: An inception-ResNet feature reconstruction model for building segmentation](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I1x3S4gAAAAJ&authuser=1&citation_for_view=I1x3S4gAAAAJ:ufrVoPGSRksC), K Xu, L Nie, Z Zhang et al. 



# üéñ Honors and Awards
- *2025.01* Received funding from the 2024 China Association for Science and Technology Young Talent Support Project Doctoral Special Program
- *2024.09* National Scholarships for PhD Candidates. 
- *2022.09* National Scholarships for Postgraduate Students. 
- *2022.04* CLIC video compression PSNR ranked fourth. 
- *2019.06* Learning-Based Image Inpainting Runner Award. 

# üìñ Educations
- *2023.09 - 2027.06(now)*, Ph.D, Xidian University, Xi'an.
- *2020.09 - 2023.06*, Master, Xidian University, Xi'an.
- *2016.09 - 2020.06*, Information and Computing Science, Southwest University of Science and Technology, Mianyang.


# üí¨ Invited Talks
<!-- - *2024.04*, Image Transmission Institute talk (End-to-End Camera Imaging). -->

- *2024.08*,  video face restoration IJCAI oral presentation.
- *2024.04*,  video enhancement technology Alipay internal talk.
- *2024.04*, HDR video generation and quality assessment technology Alipay internal talk.
- *2024.04*, HDR video generation and quality assessment technology Alipay internal talk.
- *2024.01*, Real World HDR video generation technology Alipay internal talk.
- *2022.10*, HDR video generation technology talk ACM MM.
- *2022.08*, HDR video generation key technology solves MEGVII internal talk.
- *2022.05*, Talk 3D Rendering Course. 
- *2022.06*, HDR video generation technology MEGVII internal talk.
- *2022.06*, Video compression technology solution talk, CLIC2022 (CVPR).
<!-- - *Test*,   \| [\[video\]](https://github.com/) -->

# üíª Internships
- *2022.05 - 2022.10*, [MEGVII], China.
